{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aamir/.local/share/virtualenvs/CurePilot-Mzm1XPrs/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for codeparrot/xlcost-text-to-code contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/codeparrot/xlcost-text-to-code\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 7.61k/7.61k [00:00<00:00, 34.4MB/s]\n",
      "Downloading readme: 100%|██████████| 3.32k/3.32k [00:00<00:00, 28.3MB/s]\n",
      "Downloading data: 100%|██████████| 12.2M/12.2M [00:01<00:00, 8.59MB/s]\n",
      "Downloading data: 100%|██████████| 1.08M/1.08M [00:00<00:00, 4.06MB/s]\n",
      "Downloading data: 100%|██████████| 599k/599k [00:00<00:00, 4.13MB/s]\n",
      "Generating train split: 81207 examples [00:00, 101666.64 examples/s]\n",
      "Generating test split: 7293 examples [00:00, 104580.84 examples/s]\n",
      "Generating validation split: 3946 examples [00:00, 100011.62 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 81207/81207 [00:00<00:00, 4982473.12 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 7293/7293 [00:00<00:00, 2440681.33 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 3946/3946 [00:00<00:00, 1674835.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# loading the whole dataset without splits\n",
    "from datasets import load_dataset\n",
    "dataset_name = \"codeparrot/xlcost-text-to-code\"\n",
    "output_dir = '/mnt/nvme1n1/Aamir/datasets/xlcost-text-to-code'\n",
    "dataset = load_dataset(dataset_name)\n",
    "dataset.save_to_disk(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading a particular split of a dataset \n",
    "from datasets import load_dataset\n",
    "dataset_name = \"nampdn-ai/tiny-codes\"\n",
    "output_dir = '/mnt/nvme1n1/Aamir/datasets/tiny-codes'\n",
    "dataset = load_dataset(dataset_name, split='train')\n",
    "dataset.save_to_disk(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 187398/187398 [00:00<00:00, 4004035.50 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 17092/17092 [00:00<00:00, 2498920.94 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 9345/9345 [00:00<00:00, 1995406.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# loading a dataset with multiple subsets\n",
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "dataset_name = \"codeparrot/xlcost-text-to-code\"\n",
    "subsets = ['Python-snippet-level', 'Python-program-level', 'Csharp-snippet-level', 'Csharp-program-level']\n",
    "\n",
    "# Initialize lists to hold the different splits\n",
    "train_splits = []\n",
    "test_splits = []\n",
    "validation_splits = []\n",
    "\n",
    "# Load the splits for each subset and append them to the respective lists\n",
    "for subset in subsets:\n",
    "    dataset = load_dataset(dataset_name, subset)\n",
    "    train_splits.append(dataset['train'])\n",
    "    test_splits.append(dataset['test'])\n",
    "    validation_splits.append(dataset['validation'])\n",
    "\n",
    "# Concatenate the splits\n",
    "train_combined = concatenate_datasets(train_splits)\n",
    "test_combined = concatenate_datasets(test_splits)\n",
    "validation_combined = concatenate_datasets(validation_splits)\n",
    "\n",
    "# Combine into a single dataset\n",
    "combined_dataset = DatasetDict({\n",
    "    'train': train_combined,\n",
    "    'test': test_combined,\n",
    "    'validation': validation_combined\n",
    "})\n",
    "\n",
    "output_dir = '/mnt/nvme1n1/Aamir/datasets/xlcost-text-to-code'\n",
    "combined_dataset.save_to_disk(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CurePilot-Mzm1XPrs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
